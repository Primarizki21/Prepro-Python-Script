{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tes Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typer\n",
    "import pandas as pd\n",
    "import re\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "import pycountry\n",
    "from spellchecker import SpellChecker\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Raw Data/custdirty_data.csv\")\n",
    "df2 = pd.read_csv(\"Raw Data/government_citizenship_dirty.csv\")\n",
    "df3 = pd.read_csv(\"Raw Data/hospital_data_dirty.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Purchase_Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone_Number</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CUST_001</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Mar 05 2024</td>\n",
       "      <td>65.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Today, federal, claim, report, consider, publi...</td>\n",
       "      <td>USA</td>\n",
       "      <td>250518 1271</td>\n",
       "      <td>eric82@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CUST_002</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>May 29 2024</td>\n",
       "      <td>335.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alone appear example.</td>\n",
       "      <td>Canada</td>\n",
       "      <td>891.222.8992x0833</td>\n",
       "      <td>allentodd@example.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CUST_003</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>May 28 2024</td>\n",
       "      <td>106.92</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DIRECTION, SECURITY, WHO, GROUND, TRIP, ROOM. ...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>(926)729-9917x4080</td>\n",
       "      <td>oschultz@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CUST_004</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Jun 30 2024</td>\n",
       "      <td>389.70</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Answer, huge, six, new, tough. - picture</td>\n",
       "      <td>Canada</td>\n",
       "      <td>(421)698-4215x479</td>\n",
       "      <td>ajohnson@example.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CUST_005</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>14/10/2024</td>\n",
       "      <td>140.78</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Recent last economic establish understand.</td>\n",
       "      <td>Canada</td>\n",
       "      <td>294283 6286</td>\n",
       "      <td>andersonsheriexample.org.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>7431</td>\n",
       "      <td>CUST_7431</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Feb 24 2024</td>\n",
       "      <td>445.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Meeting, adult, choose, customer, see, base. -...</td>\n",
       "      <td>USA</td>\n",
       "      <td>785235 4238x89420</td>\n",
       "      <td>erinleon@example.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>940</td>\n",
       "      <td>CUST_940</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Jun 13 2024</td>\n",
       "      <td>188.90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Actually home blue get.</td>\n",
       "      <td>Usa</td>\n",
       "      <td>380 450 1416x0693</td>\n",
       "      <td>obrienmichael@example.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>9519</td>\n",
       "      <td>CUST_9519</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Apr 04 2024</td>\n",
       "      <td>371.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Option stand determine course include.</td>\n",
       "      <td>Usa</td>\n",
       "      <td>434 895 9812</td>\n",
       "      <td>brownjames@example.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>1804</td>\n",
       "      <td>CUST_1804</td>\n",
       "      <td>Books</td>\n",
       "      <td>May 06 2024</td>\n",
       "      <td>165.60</td>\n",
       "      <td>18.0</td>\n",
       "      <td>ACCOUNT, AFFECT, NIGHT. - ATTACK</td>\n",
       "      <td>CAN</td>\n",
       "      <td>8682519899</td>\n",
       "      <td>thomas86@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>8721</td>\n",
       "      <td>CUST_8721</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>90.66</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Fall, task, vote, remain, my, score. - toward</td>\n",
       "      <td>Usa</td>\n",
       "      <td>(258)677-4853x19920</td>\n",
       "      <td>kyle30@example.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10300 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID CustomerID Product_Category Purchase_Date   Price  Quantity  \\\n",
       "0         1   CUST_001      Electronics   Mar 05 2024   65.58      11.0   \n",
       "1         2   CUST_002      Electronics   May 29 2024  335.85       1.0   \n",
       "2         3   CUST_003      Electronics   May 28 2024  106.92      19.0   \n",
       "3         4   CUST_004         Clothing   Jun 30 2024  389.70       6.0   \n",
       "4         5   CUST_005        Furniture    14/10/2024  140.78      14.0   \n",
       "...     ...        ...              ...           ...     ...       ...   \n",
       "10295  7431  CUST_7431        Furniture   Feb 24 2024  445.08       6.0   \n",
       "10296   940   CUST_940         Clothing   Jun 13 2024  188.90       9.0   \n",
       "10297  9519  CUST_9519         Clothing   Apr 04 2024  371.88       NaN   \n",
       "10298  1804  CUST_1804            Books   May 06 2024  165.60      18.0   \n",
       "10299  8721  CUST_8721         Clothing    2024-08-12   90.66       4.0   \n",
       "\n",
       "                                     Product_Description         Country  \\\n",
       "0      Today, federal, claim, report, consider, publi...             USA   \n",
       "1                                  Alone appear example.          Canada   \n",
       "2      DIRECTION, SECURITY, WHO, GROUND, TRIP, ROOM. ...  United Kingdom   \n",
       "3               Answer, huge, six, new, tough. - picture          Canada   \n",
       "4             Recent last economic establish understand.          Canada   \n",
       "...                                                  ...             ...   \n",
       "10295  Meeting, adult, choose, customer, see, base. -...             USA   \n",
       "10296                            Actually home blue get.             Usa   \n",
       "10297             Option stand determine course include.             Usa   \n",
       "10298                   ACCOUNT, AFFECT, NIGHT. - ATTACK             CAN   \n",
       "10299      Fall, task, vote, remain, my, score. - toward             Usa   \n",
       "\n",
       "              Phone_Number                      Email  \n",
       "0              250518 1271         eric82@example.com  \n",
       "1        891.222.8992x0833      allentodd@example.org  \n",
       "2       (926)729-9917x4080       oschultz@example.com  \n",
       "3        (421)698-4215x479       ajohnson@example.org  \n",
       "4              294283 6286  andersonsheriexample.org.  \n",
       "...                    ...                        ...  \n",
       "10295    785235 4238x89420       erinleon@example.net  \n",
       "10296    380 450 1416x0693  obrienmichael@example.org  \n",
       "10297         434 895 9812     brownjames@example.net  \n",
       "10298           8682519899       thomas86@example.com  \n",
       "10299  (258)677-4853x19920         kyle30@example.org  \n",
       "\n",
       "[10300 rows x 10 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitizenID</th>\n",
       "      <th>Name</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Address</th>\n",
       "      <th>VotingStatus</th>\n",
       "      <th>PassportNumber</th>\n",
       "      <th>TaxID</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>CriminalRecord</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Income</th>\n",
       "      <th>ImmigrationYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIT_001</td>\n",
       "      <td>Allen Novak</td>\n",
       "      <td>1968-06-16</td>\n",
       "      <td>USA</td>\n",
       "      <td>597 Carr Creek Apt. 464; West Andrew; NE 76236,</td>\n",
       "      <td>No</td>\n",
       "      <td>460200468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>HS</td>\n",
       "      <td>42533.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIT_002</td>\n",
       "      <td>TAMARA RAMSEY</td>\n",
       "      <td>1987-02-11</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>3899 Medina Roads; Crystaltown; NY 04112,</td>\n",
       "      <td>No</td>\n",
       "      <td>INVALID_our</td>\n",
       "      <td>TAX-002-36</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>Masters</td>\n",
       "      <td>28175.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIT_003</td>\n",
       "      <td>David Williams</td>\n",
       "      <td>1937-12-15</td>\n",
       "      <td>Bharat</td>\n",
       "      <td>03064 Eric Ferry; Port Rebecca; AZ 09961,</td>\n",
       "      <td>Y</td>\n",
       "      <td>E48182721</td>\n",
       "      <td>TAX-003-03</td>\n",
       "      <td>Widowed</td>\n",
       "      <td></td>\n",
       "      <td>High School</td>\n",
       "      <td>143299.35</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIT_004</td>\n",
       "      <td>Desiree Willis</td>\n",
       "      <td>1991-03-24</td>\n",
       "      <td>USA</td>\n",
       "      <td>773 Perry Flats; East Michael; WY 77221,</td>\n",
       "      <td>Y</td>\n",
       "      <td>O98365870</td>\n",
       "      <td>TAX_004_11</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>105629.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIT_005</td>\n",
       "      <td>Terry Gill</td>\n",
       "      <td>2000-10-15</td>\n",
       "      <td>FR</td>\n",
       "      <td>214 Michael Crescent Suite 393, New Paulport, ...</td>\n",
       "      <td>N</td>\n",
       "      <td>R72171677</td>\n",
       "      <td>TAX-005-00</td>\n",
       "      <td>S</td>\n",
       "      <td>Pending</td>\n",
       "      <td>PhD</td>\n",
       "      <td>117985.07</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>CIT_3673</td>\n",
       "      <td>Scott Barrett</td>\n",
       "      <td>1950-03-08</td>\n",
       "      <td>IND</td>\n",
       "      <td>10041 Fisher Row Suite 135, Lake Anneburgh, GA...</td>\n",
       "      <td>N</td>\n",
       "      <td>407208444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td></td>\n",
       "      <td>PhD</td>\n",
       "      <td>99415.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>CIT_8693</td>\n",
       "      <td>JAMES BROWN</td>\n",
       "      <td>2000-12-13</td>\n",
       "      <td>US</td>\n",
       "      <td>563 Romero Ferry, Petersonport, OR 06511</td>\n",
       "      <td>N</td>\n",
       "      <td>983829316</td>\n",
       "      <td>TAX-8693-20</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PhD</td>\n",
       "      <td>128327.81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>CIT_7140</td>\n",
       "      <td>Susan Beck</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>US</td>\n",
       "      <td>31275 Michelle Well Suite 725, West Randytown,...</td>\n",
       "      <td></td>\n",
       "      <td>INVALID_enjoy</td>\n",
       "      <td>TAX-7140-50</td>\n",
       "      <td>Single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>26909.17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>CIT_779</td>\n",
       "      <td>JACKSON STOUT</td>\n",
       "      <td>1983-08-18</td>\n",
       "      <td>India</td>\n",
       "      <td>10300 Michelle Passage, Amandaburgh, RI 93986</td>\n",
       "      <td>Registered</td>\n",
       "      <td>O91186652</td>\n",
       "      <td>TAX-779-15</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>High School</td>\n",
       "      <td>132278.13</td>\n",
       "      <td>1969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>CIT_2923</td>\n",
       "      <td>DAWN LANE</td>\n",
       "      <td>2002-12-23</td>\n",
       "      <td>United States</td>\n",
       "      <td>07158 Tamara Drives Apt. 970, Brooksfurt, CT 3...</td>\n",
       "      <td>No</td>\n",
       "      <td>S29245729</td>\n",
       "      <td>TAX-2923-67</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PhD</td>\n",
       "      <td>52938.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CitizenID            Name   BirthDate    Nationality  \\\n",
       "0       CIT_001     Allen Novak  1968-06-16            USA   \n",
       "1       CIT_002   TAMARA RAMSEY  1987-02-11         FRANCE   \n",
       "2       CIT_003  David Williams  1937-12-15         Bharat   \n",
       "3       CIT_004  Desiree Willis  1991-03-24            USA   \n",
       "4       CIT_005      Terry Gill  2000-10-15             FR   \n",
       "...         ...             ...         ...            ...   \n",
       "10495  CIT_3673   Scott Barrett  1950-03-08            IND   \n",
       "10496  CIT_8693     JAMES BROWN  2000-12-13             US   \n",
       "10497  CIT_7140      Susan Beck  2001-05-11             US   \n",
       "10498   CIT_779   JACKSON STOUT  1983-08-18          India   \n",
       "10499  CIT_2923       DAWN LANE  2002-12-23  United States   \n",
       "\n",
       "                                                 Address VotingStatus  \\\n",
       "0        597 Carr Creek Apt. 464; West Andrew; NE 76236,           No   \n",
       "1              3899 Medina Roads; Crystaltown; NY 04112,           No   \n",
       "2              03064 Eric Ferry; Port Rebecca; AZ 09961,            Y   \n",
       "3               773 Perry Flats; East Michael; WY 77221,            Y   \n",
       "4      214 Michael Crescent Suite 393, New Paulport, ...            N   \n",
       "...                                                  ...          ...   \n",
       "10495  10041 Fisher Row Suite 135, Lake Anneburgh, GA...            N   \n",
       "10496           563 Romero Ferry, Petersonport, OR 06511            N   \n",
       "10497  31275 Michelle Well Suite 725, West Randytown,...                \n",
       "10498      10300 Michelle Passage, Amandaburgh, RI 93986   Registered   \n",
       "10499  07158 Tamara Drives Apt. 970, Brooksfurt, CT 3...           No   \n",
       "\n",
       "      PassportNumber        TaxID MaritalStatus CriminalRecord EducationLevel  \\\n",
       "0          460200468          NaN       Married             No             HS   \n",
       "1        INVALID_our   TAX-002-36             S             No        Masters   \n",
       "2          E48182721   TAX-003-03       Widowed                   High School   \n",
       "3          O98365870   TAX_004_11       Married             No      Doctorate   \n",
       "4          R72171677   TAX-005-00             S        Pending            PhD   \n",
       "...              ...          ...           ...            ...            ...   \n",
       "10495      407208444          NaN       Unknown                           PhD   \n",
       "10496      983829316  TAX-8693-20       Unknown            NaN            PhD   \n",
       "10497  INVALID_enjoy  TAX-7140-50        Single            Yes    High School   \n",
       "10498      O91186652   TAX-779-15             S             No    High School   \n",
       "10499      S29245729  TAX-2923-67       Married            Yes            PhD   \n",
       "\n",
       "          Income  ImmigrationYear  \n",
       "0       42533.54              NaN  \n",
       "1       28175.78              NaN  \n",
       "2      143299.35           1986.0  \n",
       "3      105629.33              NaN  \n",
       "4      117985.07           2005.0  \n",
       "...          ...              ...  \n",
       "10495   99415.01              NaN  \n",
       "10496  128327.81              NaN  \n",
       "10497   26909.17              NaN  \n",
       "10498  132278.13           1969.0  \n",
       "10499   52938.39              NaN  \n",
       "\n",
       "[10500 rows x 13 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>AdmissionDate</th>\n",
       "      <th>DischargeDate</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Department</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BloodType</th>\n",
       "      <th>Medication</th>\n",
       "      <th>TestResults</th>\n",
       "      <th>BillingAmount</th>\n",
       "      <th>InsuranceProvider</th>\n",
       "      <th>AppointmentDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT_001</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>Appendicitis</td>\n",
       "      <td>Special with job,</td>\n",
       "      <td>Carl Beard</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>81</td>\n",
       "      <td>Female</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85/67</td>\n",
       "      <td>9495.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT_K_2</td>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>Certainly way ten,</td>\n",
       "      <td>Mary Sanchez</td>\n",
       "      <td>Endo</td>\n",
       "      <td>-88</td>\n",
       "      <td>M</td>\n",
       "      <td>O-</td>\n",
       "      <td>civil</td>\n",
       "      <td>140/118</td>\n",
       "      <td>8681.08</td>\n",
       "      <td>HC Insurance</td>\n",
       "      <td>2023-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT_003</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>2025-04-29</td>\n",
       "      <td>Appendicitis</td>\n",
       "      <td>Study small,</td>\n",
       "      <td>Mr. Patrick Harris MD</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>94</td>\n",
       "      <td>M</td>\n",
       "      <td>O-</td>\n",
       "      <td>word</td>\n",
       "      <td>92/95</td>\n",
       "      <td>2829.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT_004</td>\n",
       "      <td>Mar 11 1978</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>COPD</td>\n",
       "      <td>Investment human,</td>\n",
       "      <td>Donald Roach</td>\n",
       "      <td>Endocrinology</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>A+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140/119</td>\n",
       "      <td>1121.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT_005</td>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Every coach,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ortho</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>B-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71/68</td>\n",
       "      <td>5555.75</td>\n",
       "      <td>HC Insurance</td>\n",
       "      <td>2023-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>PT_691</td>\n",
       "      <td>2024-03-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COPD</td>\n",
       "      <td>Focus population green,</td>\n",
       "      <td>Jennifer Rodriguez</td>\n",
       "      <td>Cardio</td>\n",
       "      <td>68</td>\n",
       "      <td>Female</td>\n",
       "      <td>O+</td>\n",
       "      <td>step</td>\n",
       "      <td>High</td>\n",
       "      <td>5014.95</td>\n",
       "      <td>HealthPlus</td>\n",
       "      <td>2024-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>PT_7247</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>Hold,</td>\n",
       "      <td>Christine Morris</td>\n",
       "      <td>Ortho</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>O-</td>\n",
       "      <td>floor 1 units</td>\n",
       "      <td>98/68</td>\n",
       "      <td>8152.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>PT_4814</td>\n",
       "      <td>Oct 11 1998</td>\n",
       "      <td>2005-04-22</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>Imagine power PM,</td>\n",
       "      <td>Luis May</td>\n",
       "      <td>Endocrinology</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>A+</td>\n",
       "      <td>senior</td>\n",
       "      <td>181/80</td>\n",
       "      <td>2323.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>PT_8633</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>Dyabetes</td>\n",
       "      <td>Morning body than,</td>\n",
       "      <td>Jamie King</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>AB+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169/46</td>\n",
       "      <td>3466.39</td>\n",
       "      <td>HealthPlus</td>\n",
       "      <td>2024-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>PT_2977</td>\n",
       "      <td>Mar 31 2017</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>COPD</td>\n",
       "      <td>Notice after staff,</td>\n",
       "      <td>Thomas Perry</td>\n",
       "      <td>Cardilogy</td>\n",
       "      <td>89</td>\n",
       "      <td>U</td>\n",
       "      <td>A+</td>\n",
       "      <td>edge</td>\n",
       "      <td>72/46</td>\n",
       "      <td>5592.93</td>\n",
       "      <td>MediCare</td>\n",
       "      <td>2024-01-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10300 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientID AdmissionDate DischargeDate     Diagnosis  \\\n",
       "0        PT_001    2024-10-03    2025-05-11  Appendicitis   \n",
       "1        PT_K_2    2023-06-27    2023-12-05      Fracture   \n",
       "2        PT_003    2024-05-18    2025-04-29  Appendicitis   \n",
       "3        PT_004   Mar 11 1978    2019-10-26          COPD   \n",
       "4        PT_005    2024-11-23    2024-12-02      Diabetes   \n",
       "...         ...           ...           ...           ...   \n",
       "10295    PT_691    2024-03-16           NaN          COPD   \n",
       "10296   PT_7247    2023-03-29    2024-10-27      Fracture   \n",
       "10297   PT_4814   Oct 11 1998    2005-04-22      Fracture   \n",
       "10298   PT_8633    2024-02-01    2024-11-28      Dyabetes   \n",
       "10299   PT_2977   Mar 31 2017    2018-02-01          COPD   \n",
       "\n",
       "                     Treatment                 Doctor     Department  Age  \\\n",
       "0            Special with job,             Carl Beard    Orthopedics   81   \n",
       "1           Certainly way ten,           Mary Sanchez           Endo  -88   \n",
       "2                 Study small,  Mr. Patrick Harris MD    Orthopedics   94   \n",
       "3            Investment human,           Donald Roach  Endocrinology   26   \n",
       "4                 Every coach,                    NaN          Ortho   35   \n",
       "...                        ...                    ...            ...  ...   \n",
       "10295  Focus population green,     Jennifer Rodriguez         Cardio   68   \n",
       "10296                    Hold,       Christine Morris          Ortho   15   \n",
       "10297        Imagine power PM,               Luis May  Endocrinology    3   \n",
       "10298       Morning body than,             Jamie King     Cardiology   52   \n",
       "10299      Notice after staff,           Thomas Perry      Cardilogy   89   \n",
       "\n",
       "       Gender BloodType     Medication TestResults  BillingAmount  \\\n",
       "0      Female        B+            NaN       85/67        9495.73   \n",
       "1           M        O-          civil     140/118        8681.08   \n",
       "2           M        O-           word       92/95        2829.42   \n",
       "3           F        A+            NaN     140/119        1121.27   \n",
       "4      Female        B-            NaN       71/68        5555.75   \n",
       "...       ...       ...            ...         ...            ...   \n",
       "10295  Female        O+           step        High        5014.95   \n",
       "10296       F        O-  floor 1 units       98/68        8152.91   \n",
       "10297    Male        A+         senior      181/80        2323.13   \n",
       "10298       M       AB+            NaN      169/46        3466.39   \n",
       "10299       U        A+           edge       72/46        5592.93   \n",
       "\n",
       "      InsuranceProvider AppointmentDate  \n",
       "0                   NaN      2024-02-17  \n",
       "1          HC Insurance      2023-08-08  \n",
       "2                   NaN      2024-05-21  \n",
       "3                   NaN      2024-11-03  \n",
       "4          HC Insurance      2023-11-14  \n",
       "...                 ...             ...  \n",
       "10295        HealthPlus      2024-04-21  \n",
       "10296               NaN      2023-12-14  \n",
       "10297               NaN      2024-06-13  \n",
       "10298        HealthPlus      2024-06-26  \n",
       "10299          MediCare      2024-01-24  \n",
       "\n",
       "[10300 rows x 15 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Appendicitis', 'Fracture', 'COPD', 'Diabetes', 'Hypertension',\n",
       "       'copd', 'appendicitis', 'Hypertensyon', 'Dyabetes', 'Appendycytys',\n",
       "       'hypertension', 'fracture', 'diabetes'], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                        0\n",
      "CustomerID              514\n",
      "Product_Category       1309\n",
      "Purchase_Date             0\n",
      "Price                     0\n",
      "Quantity                765\n",
      "Product_Description       0\n",
      "Country                   0\n",
      "Phone_Number              0\n",
      "Email                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CitizenID             0\n",
      "Name                  0\n",
      "BirthDate             0\n",
      "Nationality           0\n",
      "Address               0\n",
      "VotingStatus          0\n",
      "PassportNumber        0\n",
      "TaxID              1082\n",
      "MaritalStatus         0\n",
      "CriminalRecord     2093\n",
      "EducationLevel        0\n",
      "Income                0\n",
      "ImmigrationYear    7893\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientID               0\n",
      "AdmissionDate           0\n",
      "DischargeDate        3052\n",
      "Diagnosis               0\n",
      "Treatment               0\n",
      "Doctor               1059\n",
      "Department              0\n",
      "Age                     0\n",
      "Gender                  0\n",
      "BloodType               0\n",
      "Medication           4151\n",
      "TestResults             0\n",
      "BillingAmount           0\n",
      "InsuranceProvider    3685\n",
      "AppointmentDate         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df3.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolom ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10300"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF 1 ['ID', 'CustomerID']\n",
      "DF 2 ['CitizenID', 'TaxID']\n",
      "DF 3 ['PatientID']\n"
     ]
    }
   ],
   "source": [
    "def apakah_kolom_id(kolom):\n",
    "    pattern = r'(id)[_A-Z]?'\n",
    "    return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_id(df, threshold = 0.7):\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        if (ratio >= threshold) and apakah_kolom_id(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "print(f\"DF 1 {identifikasi_kolom_id(df1)}\")\n",
    "print(f\"DF 2 {identifikasi_kolom_id(df2)}\")\n",
    "print(f\"DF 3 {identifikasi_kolom_id(df3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Category       1309\n",
      "Purchase_Date             0\n",
      "Price                     0\n",
      "Quantity                765\n",
      "Product_Description       0\n",
      "Country                   0\n",
      "Phone_Number              0\n",
      "Email                     0\n",
      "dtype: int64\n",
      "Name                  0\n",
      "BirthDate             0\n",
      "Nationality           0\n",
      "Address               0\n",
      "VotingStatus          0\n",
      "PassportNumber        0\n",
      "MaritalStatus         0\n",
      "CriminalRecord     2093\n",
      "EducationLevel        0\n",
      "Income                0\n",
      "ImmigrationYear    7893\n",
      "dtype: int64\n",
      "AdmissionDate           0\n",
      "DischargeDate        3052\n",
      "Diagnosis               0\n",
      "Treatment               0\n",
      "Doctor               1059\n",
      "Department              0\n",
      "Age                     0\n",
      "Gender                  0\n",
      "BloodType               0\n",
      "Medication           4151\n",
      "TestResults             0\n",
      "BillingAmount           0\n",
      "InsuranceProvider    3685\n",
      "AppointmentDate         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kolom_id1 = identifikasi_kolom_id(df1)\n",
    "kolom_id2 = identifikasi_kolom_id(df2)\n",
    "kolom_id3 = identifikasi_kolom_id(df3)\n",
    "\n",
    "# df11 = df1.copy()\n",
    "# df22 = df2.copy()\n",
    "# df33 = df3.copy()\n",
    "\n",
    "df1 = df1.drop(columns=kolom_id1)\n",
    "df2 = df2.drop(columns=kolom_id2)\n",
    "df3 = df3.drop(columns=kolom_id3)\n",
    "\n",
    "print(df1.isna().sum())\n",
    "print(df2.isna().sum())\n",
    "print(df3.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Nama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Allen Novak\n",
       "1         Tamara Ramsey\n",
       "2        David Williams\n",
       "3        Desiree Willis\n",
       "4            Terry Gill\n",
       "              ...      \n",
       "10495     Scott Barrett\n",
       "10496       James Brown\n",
       "10497        Susan Beck\n",
       "10498     Jackson Stout\n",
       "10499         Dawn Lane\n",
       "Name: Name, Length: 10500, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apakah_kolom_nama(kolom):\n",
    "    pattern = r'(name|nama|pengguna)[_A-Z]?'\n",
    "    return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_nama(df, threshold = 0.7):\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        if (ratio >= threshold) and apakah_kolom_nama(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "    \n",
    "kolom_nama = identifikasi_kolom_nama(df2)\n",
    "\n",
    "def format_name(name):\n",
    "    return name.title()\n",
    "\n",
    "for kolom in kolom_nama:\n",
    "    df2[kolom] = df2[kolom].apply(format_name)\n",
    "\n",
    "df2['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Tanggal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Mar 05 2024\n",
       "1        May 29 2024\n",
       "2        May 28 2024\n",
       "3        Jun 30 2024\n",
       "4         14/10/2024\n",
       "            ...     \n",
       "10295    Feb 24 2024\n",
       "10296    Jun 13 2024\n",
       "10297    Apr 04 2024\n",
       "10298    May 06 2024\n",
       "10299     2024-08-12\n",
       "Name: Purchase_Date, Length: 10300, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Purchase_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1968-06-16\n",
       "1        1987-02-11\n",
       "2        1937-12-15\n",
       "3        1991-03-24\n",
       "4        2000-10-15\n",
       "            ...    \n",
       "10495    1950-03-08\n",
       "10496    2000-12-13\n",
       "10497    2001-05-11\n",
       "10498    1983-08-18\n",
       "10499    2002-12-23\n",
       "Name: BirthDate, Length: 10500, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"BirthDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df2[\"BirthDate\"].dtype == \"datetime64[ns]\":\n",
    "    print(\"mantap\")\n",
    "# df1['updateorder'] = np.random.randint(1, 101, size=len(df1))\n",
    "# df1['purchasedate'] = np.random.randint(1, 101, size=len(df1))\n",
    "# df1['updateorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006796116504854369\n",
      "None\n",
      "0.10660194174757281\n",
      "<re.Match object; span=(8, 13), match='_Date'>\n",
      "0.8632038834951457\n",
      "None\n",
      "0.0018446601941747574\n",
      "None\n",
      "0.970873786407767\n",
      "None\n",
      "0.0006796116504854369\n",
      "None\n",
      "0.970873786407767\n",
      "None\n",
      "0.9544660194174758\n",
      "None\n",
      "['Purchase_Date']\n",
      "['BirthDate']\n",
      "['AdmissionDate', 'DischargeDate', 'AppointmentDate']\n"
     ]
    }
   ],
   "source": [
    "def apakah_kolom_date(kolom):\n",
    "    \"\"\"\n",
    "    Apakah Kolom Tanggal?\n",
    "    Pola kata dari kolom yang ingin dihapus\n",
    "    Mencari kolom dengan pola kata \"date\" dll\n",
    "    \"\"\"\n",
    "    pattern1 = r'(date|tanggal|tgl|dt)\\b|_(date|tanggal|tgl|dt)[_A-Z]?'\n",
    "    verif1 = re.search(pattern1, kolom, re.IGNORECASE)\n",
    "    # verif2 = re.search(pattern2, kolom, re.IGNORECASE)\n",
    "    return verif1\n",
    "    # return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_date(df):\n",
    "    \"\"\"\n",
    "    Identifikasi Kolom ID\n",
    "    \"\"\"\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        if apakah_kolom_date(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "for x in df1.columns:\n",
    "    ratio = df1[x].nunique() / len(df1)\n",
    "    print(ratio)\n",
    "    print(apakah_kolom_date(x))\n",
    "print(identifikasi_kolom_date(df1))\n",
    "print(identifikasi_kolom_date(df2))\n",
    "print(identifikasi_kolom_date(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Purchase_Date']\n",
      "['BirthDate']\n",
      "['AdmissionDate', 'DischargeDate', 'AppointmentDate']\n"
     ]
    }
   ],
   "source": [
    "formats = [\n",
    "    '%d/%m/%y',  # dd/mm/yy\n",
    "    '%d/%m/%Y',  # dd/mm/yyyy\n",
    "    '%Y-%m-%d',  # yyyy-mm-dd\n",
    "    '%b %d %Y',  # Mmm dd yyyy\n",
    "    '%d %B %Y'   # dd Mmmm yyyy\n",
    "]\n",
    "\n",
    "def try_parsing_date(date_str, formats):\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "    \n",
    "def safe_parse(date_str):\n",
    "    date_str = str(date_str).strip()\n",
    "    try:\n",
    "        return parser.parse(date_str)\n",
    "    except (ValueError, TypeError): \n",
    "        return pd.NaT \n",
    "# kolom_date = identifikasi_kolom_date(df1)\n",
    "# for kolom in kolom_date:\n",
    "#     df1[kolom] = df1[kolom].apply(parser.parse)\n",
    "kolom_date1 = identifikasi_kolom_date(df1)\n",
    "kolom_date2 = identifikasi_kolom_date(df2)\n",
    "kolom_date3 = identifikasi_kolom_date(df3)\n",
    "\n",
    "print(kolom_date1)\n",
    "print(kolom_date2)\n",
    "print(kolom_date3)\n",
    "\n",
    "# df2['BirthDate'] = df2['BirthDate'].apply(safe_parse)\n",
    "df2['BirthDate'] = df2['BirthDate'].apply(safe_parse)\n",
    "# df2['BirthDate']\n",
    "\n",
    "# df1[\"Purchase_Date\"] = df1['Purchase_Date'].apply(parser.parse)\n",
    "# df1['Purchase_Date']\n",
    "# df1['Purchase_Date_Baru'] = df1['Purchase_Date'].apply(lambda x: try_parsing_date(x, formats))\n",
    "# df1['Purchase_Date_Baru']\n",
    "# df1['Purchase_Date_Baru'] = df1['Purchase_Date'].apply(parser.parse)\n",
    "# df1['Purchase_Date_Baru']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulan_dict = {\n",
    "#     'januari': '01', 'februari': '02', 'maret': '03', 'april': '04',\n",
    "#     'mei': '05', 'juni': '06', 'juli': '07', 'agustus': '08',\n",
    "#     'september': '09', 'oktober': '10', 'november': '11', 'desember': '12'\n",
    "# }\n",
    "# def clean_date(date_str):\n",
    "#     date_str = str(date_str).lower()\n",
    "#     for bulan, angka in bulan_dict.items():\n",
    "#         date_str = date_str.replace(bulan, angka)  # Ganti nama bulan dengan angka\n",
    "#     return date_str\n",
    "\n",
    "# df11['DateClean'] = df11['Purchase_Date'].apply(clean_date)\n",
    "# df11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kolom country\n",
      "DF 1 ['Country']\n",
      "DF 2 ['Nationality']\n",
      "DF 3 []\n"
     ]
    }
   ],
   "source": [
    "def apakah_kolom_country(kolom):\n",
    "    pattern = r'(origin|citizenship|country|nationality)\\b|_(origin|citizenship|country|nationality)[_A-Z]?'\n",
    "    return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_country(df):\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        if apakah_kolom_country(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "def apakah_kolom_telp(kolom):\n",
    "    pattern = r'\\b(phone|telp|telephone)|(phone|telp|telephone)\\b|_(phone|telp|telephone)[_A-Z]?'\n",
    "    return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_telp(df, threshold = 0.7):\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        if (ratio >= threshold) and apakah_kolom_telp(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "print(\"kolom country\")\n",
    "print(f\"DF 1 {identifikasi_kolom_country(df1)}\")\n",
    "print(f\"DF 2 {identifikasi_kolom_country(df2)}\")\n",
    "print(f\"DF 3 {identifikasi_kolom_country(df3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'Canada' 'United Kingdom' 'UK' 'CAN' 'usa' 'Usa']\n",
      "['USA' 'FRANCE' 'Bharat' 'FR' 'America' 'France' 'India' 'IND' 'US'\n",
      " 'United States']\n"
     ]
    }
   ],
   "source": [
    "print(df1['Country'].unique())\n",
    "print(df2['Nationality'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'Canada', 'United Kingdom', 'UK', 'CAN', 'usa', 'Usa'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA\n"
     ]
    }
   ],
   "source": [
    "country = \"usa\"\n",
    "country = country.upper()\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'Canada' 'United Kingdom']\n",
      "['United States' 'France' 'India']\n"
     ]
    }
   ],
   "source": [
    "special_mapping = {\n",
    "    'america': 'USA',\n",
    "    'bharat': 'IND',\n",
    "    'uk' : 'United Kingdom'\n",
    "}\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def format_country(country):\n",
    "    country = country.lower()\n",
    "    if country in special_mapping:\n",
    "        country = special_mapping[country]\n",
    "    hasil_cari = pycountry.countries.search_fuzzy(country)[0]\n",
    "    return hasil_cari.name\n",
    "\n",
    "# def format_country(country):\n",
    "#     country = country.upper()\n",
    "#     hasil_cari = pycountry.countries.search_fuzzy(country)\n",
    "#     if hasil_cari:\n",
    "#         # Pastikan hasil yang dipilih adalah yang paling tepat, misalnya berdasarkan panjang nama\n",
    "#         return max(hasil_cari, key=lambda x: len(x.name)).name\n",
    "#     return country\n",
    "\n",
    "df1['Country'] = df1['Country'].apply(format_country)\n",
    "df2['Nationality'] = df2['Nationality'].apply(format_country)\n",
    "print(df1['Country'].unique())\n",
    "print(df2['Nationality'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Nomor Telepon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kolom telp\n",
      "DF 1 ['Phone_Number']\n",
      "DF 2 []\n",
      "DF 3 []\n"
     ]
    }
   ],
   "source": [
    "print(\"kolom telp\")\n",
    "print(f\"DF 1 {identifikasi_kolom_telp(df1)}\")\n",
    "print(f\"DF 2 {identifikasi_kolom_telp(df2)}\")\n",
    "print(f\"DF 3 {identifikasi_kolom_telp(df3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "angka = [str(i) for i in range(0,10)]\n",
    "def ekstrak_simbol(baris):\n",
    "    simbol = set()\n",
    "    for nomor in baris:\n",
    "        for x in nomor:\n",
    "            if x not in angka and x not in simbol:\n",
    "                simbol.add(x)\n",
    "    return re.escape(''.join(simbol))\n",
    "\n",
    "def format_nomor(nomor, simbol, pemisah=\"-\"):\n",
    "    clean_text = re.sub(f'[{simbol}]', '', nomor)\n",
    "    chunk = []\n",
    "    for i in range(0, len(clean_text), 3):\n",
    "        chunk.append(clean_text[i:i+3])\n",
    "    hasil = pemisah.join(chunk)\n",
    "    return hasil\n",
    "\n",
    "def panjang_nomor(nomor):\n",
    "    panjang = set()\n",
    "    for x in nomor:\n",
    "        panjang.add(len(x))\n",
    "    return list(panjang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\\)\\-\\+\\.\\ \\(\n",
      "[x\\)\\-\\+\\.\\ \\(]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0              250-518-127-1\n",
       "1         891-222-899-208-33\n",
       "2         926-729-991-740-80\n",
       "3          421-698-421-547-9\n",
       "4              294-283-628-6\n",
       "                ...         \n",
       "10295    785-235-423-889-420\n",
       "10296     380-450-141-606-93\n",
       "10297          434-895-981-2\n",
       "10298          868-251-989-9\n",
       "10299    258-677-485-319-920\n",
       "Name: Phone_Number, Length: 10300, dtype: object"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil = ekstrak_simbol(df1['Phone_Number'])\n",
    "print(hasil)\n",
    "print(f'[{hasil}]')\n",
    "# hasil_panjang = panjang_nomor(df1['Phone_Number'])\n",
    "# print(hasil_panjang)\n",
    "df1['Phone_Number'] = df1['Phone_Number'].apply(lambda x:\n",
    "format_nomor(x, hasil))\n",
    "df1['Phone_Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF 1 ['Product_Category', 'Product_Description']\n",
      "DF 2 []\n",
      "DF 3 []\n"
     ]
    }
   ],
   "source": [
    "def apakah_kolom_product(kolom):\n",
    "    pattern = r'\\b(product|category|produk|kategori)|(product|category|produk|kategori)\\b|_(product|category|produk|kategori)[_A-Z]?'\n",
    "    return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_product(df):\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        if apakah_kolom_product(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "print(f\"DF 1 {identifikasi_kolom_product(df1)}\")\n",
    "print(f\"DF 2 {identifikasi_kolom_product(df2)}\")\n",
    "print(f\"DF 3 {identifikasi_kolom_product(df3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1309)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Product_Category\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronics', 'Clothing', 'Furniture', 'Sports', 'Grocery',\n",
       "       'Electornics', nan, 'Books'], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Product_Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typo_mapping = {\n",
    "#     'electornics': 'electronics',\n",
    "# }\n",
    "\n",
    "# def frequncy_dict(df, kolom):\n",
    "#     return df[kolom].value_counts().to_dict()\n",
    "\n",
    "# def format_product(produk):\n",
    "#     produk = str(produk).lower()\n",
    "#     if produk in ['na','nan']:\n",
    "#         produk = 'Unknown'\n",
    "#     if produk in typo_mapping:\n",
    "#         produk = typo_mapping[produk]\n",
    "#     return produk.title()\n",
    "\n",
    "# df1['Product_Category'] = df1['Product_Category'].apply(format_product)\n",
    "# df1['Product_Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF 1 []\n",
      "DF 2 []\n",
      "DF 3 ['Age']\n"
     ]
    }
   ],
   "source": [
    "def apakah_kolom_age(kolom):\n",
    "    pattern = r'\\b(umur|age|usia)|(umur|age|usia)\\b|_(umur|age|usia)[_A-Z]?'\n",
    "    return re.search(pattern, kolom, re.IGNORECASE)\n",
    "\n",
    "def identifikasi_kolom_age(df):\n",
    "    kolom_id = []\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        if apakah_kolom_age(kolom):\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "print(f\"DF 1 {identifikasi_kolom_age(df1)}\")\n",
    "print(f\"DF 2 {identifikasi_kolom_age(df2)}\")\n",
    "print(f\"DF 3 {identifikasi_kolom_age(df3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, -88,  94,  26,  35,  25,  54,   0,  80,   1,  10,  21,  36,\n",
       "        44,   6, -71,  61,  85,  97,  63,  31,  90,  78,  34,  93,  59,\n",
       "        32,  47,  52, -79,  77,  66,  92,  15,  33,  16,  43,   9,  20,\n",
       "        83,  24,  56,  45,   3,  79,  65,  51,  57,  95,  72,  84,  71,\n",
       "        42,  13,  22,  87,  60,   7,   4,  50, -11,  41,  74,  30,  46,\n",
       "         8,  12,  49,  17,  82,  29,  96,  38,  11,  99,  23,  88,  70,\n",
       "        73,  40,  19,  28,  53,  98,  86,  76, -95,   5,  91,  69,   2,\n",
       "        37,  64,  27, -39, -25,  14,  55,  48,  62, -28, -62,  89,  68,\n",
       "        67,  18, -99,  75, -57,  39,  58, -48, -13, -69, -58, -68, -55,\n",
       "       -24, -98, -52, -46, -29,  -1, -35, -61, -67, -56, -72, -32, -86,\n",
       "       -47, -36, -40, -22, -12, -45, -33, -91, -23, -31, -74, -97, -10,\n",
       "       -37, -83,  -2, -85, -51,  -4, -38, -17,  -8, -92, -96, -77,  -9,\n",
       "       -21, -20, -63,  -3, -59, -87, -19, -44, -75, -16, -82, -14, -90,\n",
       "       -26, -50, -27, -78, -65, -15, -53, -49,  -6, -54, -84, -93, -34,\n",
       "       -64, -76, -80, -30, -18, -60, -43, -81, -89, -94,  -5])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_age(age):\n",
    "    age = int(age)\n",
    "    if age < 0:\n",
    "        return abs(age)\n",
    "    if age == 0:\n",
    "        return age\n",
    "\n",
    "# kolom_age = identifikasi_kolom_age(df3)\n",
    "# for kolom in kolom_age:\n",
    "#     df3[kolom] = df3[kolom].apply(format_age)\n",
    "# df3['Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Kategorik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {\n",
    "    'america': 'USA',\n",
    "    'bharat': 'IND',\n",
    "    'uk': 'United Kingdom'\n",
    "}\n",
    "\n",
    "voting_mapping = {\n",
    "    'n': 'No', \n",
    "    'y': 'Yes',\n",
    "    ' ': 'Unknown',\n",
    "    '': 'Unknown',\n",
    "    np.nan: 'Unknown'\n",
    "}\n",
    "\n",
    "marital_mapping = {\n",
    "    's': 'Single',\n",
    "    'belummenikah': 'Single', \n",
    "    'janda': 'Widowed',\n",
    "    'duda': 'Widowed',\n",
    "    'cerai': 'Divorced'\n",
    "}\n",
    "\n",
    "education_mapping = {\n",
    "    'sma': 'High School',\n",
    "    'hs' : 'High School',\n",
    "    'phd' : 'Doctorate',\n",
    "    's1': 'Bachelors',\n",
    "    's2': 'Master',\n",
    "    's3': 'Doctorate'\n",
    "}\n",
    "\n",
    "gender_mapping = {\n",
    "    'm': 'Male',\n",
    "    'f': 'Female',\n",
    "    'u': 'Unknown',\n",
    "}\n",
    "blood_mapping = {\n",
    "    'positive': '+',\n",
    "    'negative': '-',\n",
    "    'positif': '+',\n",
    "    'negatif': '-',\n",
    "}\n",
    "def merge_dictionaries(*dicts):\n",
    "    merged_dict = {}\n",
    "    for dictionary in dicts:\n",
    "        merged_dict.update(dictionary)\n",
    "    return merged_dict\n",
    "\n",
    "def apakah_bloodtype(kolom):\n",
    "    akhiran = kolom.str.endswith('+') | kolom.str.endswith('-')\n",
    "    ada_kata = kolom.str.contains('positive|negative|positif|negatif', case=False, na=False)\n",
    "    return akhiran.any() | ada_kata.any()\n",
    "\n",
    "def format_bloodtype(blood, dictionary):\n",
    "    blood = blood.lower()\n",
    "    bagian = blood.split()\n",
    "    if len(bagian) == 2 and (bagian[0] in ['a', 'b', 'ab', 'o'] and bagian[1] in dictionary):\n",
    "        darah, tipe = bagian\n",
    "        tipe = dictionary.get(tipe.lower(), tipe)\n",
    "        return f\"{darah.upper()}{tipe}\"\n",
    "    elif len(bagian) == 1 and bagian[0][-1] in ['+', '-']:\n",
    "        return bagian[0].upper()\n",
    "    else:\n",
    "        return blood.upper()\n",
    "\n",
    "def replace_values_with_dict(df, dictionary):\n",
    "    for kolom in df.select_dtypes(include=['object']).columns:\n",
    "        df[kolom] = df[kolom].str.strip().str.lower()\n",
    "        df[kolom] = df[kolom].replace(dictionary)\n",
    "        \n",
    "        if apakah_bloodtype(df[kolom]):\n",
    "            df[kolom] = df[kolom].apply(lambda x: format_bloodtype(x, blood_mapping))\n",
    "        else:\n",
    "            df[kolom] = df[kolom].str.title()\n",
    "    return df\n",
    "\n",
    "merged_dict = merge_dictionaries(\n",
    "    country_mapping, \n",
    "    voting_mapping, \n",
    "    marital_mapping,\n",
    "    education_mapping,\n",
    "    gender_mapping,\n",
    "    blood_mapping\n",
    "    )\n",
    "\n",
    "df1 = replace_values_with_dict(df1, merged_dict)\n",
    "df2 = replace_values_with_dict(df2, merged_dict)\n",
    "df3 = replace_values_with_dict(df3, merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B+', 'O-', 'A+', 'B-', 'A-', 'AB-', 'AB+', 'O+'], dtype=object)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['BloodType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 'A Positive'\n",
    "# z= x.split()\n",
    "# a, b= z\n",
    "# if len(z) == 2 and (bagian[0] in ['a', 'b', 'ab', 'o'] and bagian[1] in dictionary):\n",
    "#         darah, tipe = bagian\n",
    "#         tipe = dictionary.get(tipe.lower(), tipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B+', 'O-', 'A+', 'B-', 'A-', 'AB-', 'AB+', 'O+'], dtype=object)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['BloodType'] = df3['BloodType'].apply(lambda x: format_bloodtype(x, blood_mapping))\n",
    "df3['BloodType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "Female\n",
      "Unknown\n"
     ]
    }
   ],
   "source": [
    "for x in gender_mapping.values():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPECIAL WITH JOB,' 'CERTAINLY WAY TEN,' 'STUDY SMALL,' ...\n",
      " 'OLD ENVIRONMENT OFFICIAL LEARN,' 'RECENT COMMUNITY ATTORNEY,'\n",
      " 'SOMEBODY BOTH,']\n",
      "['Female' 'Male' 'Unknown']\n",
      "['B+' 'O-' 'A+' 'B-' 'A-' 'AB-' 'AB+' 'O+']\n"
     ]
    }
   ],
   "source": [
    "print(df3[\"Treatment\"].unique())\n",
    "print(df3[\"Gender\"].unique())\n",
    "print(df3[\"BloodType\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronics' 'Clothing' 'Furniture' 'Sports' 'Grocery' 'Electornics'\n",
      " 'Unknown' 'Books']\n",
      "['Appendicitis' 'Fracture' 'Copd' 'Diabetes' 'Hypertension' 'Hypertensyon'\n",
      " 'Dyabetes' 'Appendycytys']\n"
     ]
    }
   ],
   "source": [
    "print(df1['Product_Category'].unique())\n",
    "print(df3['Diagnosis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Typo\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=4, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "# @lru_cache(maxsize=None)\n",
    "def format_typo(typo):\n",
    "    hasil = str(typo)\n",
    "    saran_typo = sym_spell.lookup(hasil, Verbosity.CLOSEST, max_edit_distance=4)\n",
    "    if saran_typo:\n",
    "        return saran_typo[0].term.title()\n",
    "    return hasil.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronics' 'Clothing' 'Furniture' 'Sports' 'Grocery' 'Unknown' 'Books']\n",
      "['Appendicitis' 'Fracture' 'Top' 'Diabetes' 'Hypertension']\n"
     ]
    }
   ],
   "source": [
    "df1['Product_Category'] = df1['Product_Category'].apply(format_typo)\n",
    "df3['Diagnosis'] = df3['Diagnosis'].apply(format_typo)\n",
    "print(df1['Product_Category'].unique())\n",
    "print(df3['Diagnosis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronics' 'Clothing' 'Furniture' 'Sports' 'Grocery' 'Unknown' 'Books']\n",
      "['Appendicitis' 'Fracture' 'Top' 'Diabetes' 'Hypertension']\n"
     ]
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=4, prefix_length=10)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "kata_benar = {\n",
    "}\n",
    "def format_typo(typo):\n",
    "    if typo in kata_benar:\n",
    "        return kata_benar[typo].title()\n",
    "    saran_typo = sym_spell.lookup(typo, Verbosity.CLOSEST, max_edit_distance=4)\n",
    "    if saran_typo:\n",
    "        jawaban_benar = saran_typo[0].term.title()\n",
    "    else: \n",
    "        jawaban_benar = typo.title()\n",
    "    kata_benar[typo] = jawaban_benar\n",
    "    return jawaban_benar\n",
    "\n",
    "def correct_typo(series):\n",
    "    return series.apply(format_typo)\n",
    "\n",
    "# sym_spell = SymSpell(max_dictionary_edit_distance=4, prefix_length=7)\n",
    "# dictionary_path = pkg_resources.resource_filename(\n",
    "#     \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "# sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "# @lru_cache(maxsize=None)\n",
    "# def format_typo(typo):\n",
    "#     hasil = str(typo)\n",
    "#     saran_typo = sym_spell.lookup(hasil, Verbosity.CLOSEST, max_edit_distance=4)\n",
    "#     if saran_typo:\n",
    "#         return saran_typo[0].term.title()\n",
    "#     return hasil.title()\n",
    "\n",
    "# df1['Product_Category'] = df1['Product_Category'].apply(format_typo)\n",
    "df1['Product_Category'] = correct_typo(df1['Product_Category'])\n",
    "df3['Diagnosis'] = correct_typo(df3['Diagnosis'])\n",
    "print(df1['Product_Category'].unique())\n",
    "# df3['Diagnosis'] = df3['Diagnosis'].apply(format_typo)\n",
    "print(df3['Diagnosis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=10)\n",
    "typo = 'copd'\n",
    "saran_typo = sym_spell.lookup(typo, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "print(saran_typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell = SpellChecker()\n",
    "# @lru_cache(maxsize=None)\n",
    "# def format_typo(typo):\n",
    "#     hasil = str(spell.correction(typo))\n",
    "#     if hasil.lower() == 'none':\n",
    "#         return f\"{typo} ini woy\"\n",
    "#     return hasil.title()\n",
    "\n",
    "# df1['Product_Category'] = df1['Product_Category'].apply(format_typo)\n",
    "# print(df1['Product_Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def apakah_bloodtype(kolom):\n",
    "    akhiran = kolom.str.endswith('+') | kolom.str.endswith('-')\n",
    "    # ada_kata = kolom.str.contains('positive|negative|positif|negatif', case=False, na=False)\n",
    "    return akhiran.any()\n",
    "\n",
    "hasil = apakah_bloodtype(df3['Medication'])\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_missing_dict_values(series, dictionary, process_func):\n",
    "    \"\"\"\n",
    "    Check if values in a series are not in dictionary and apply a function\n",
    "    \n",
    "    Parameters:\n",
    "    series: pandas Series to check\n",
    "    dictionary: dictionary containing valid values\n",
    "    process_func: function to apply to values not in dictionary\n",
    "    \"\"\"\n",
    "    # Create mask for values not in dictionary\n",
    "    mask = ~series.str.lower().isin([k.lower() for k in dictionary.keys()])\n",
    "    \n",
    "    # Apply function only to values not in dictionary\n",
    "    series.loc[mask] = series.loc[mask].apply(process_func)\n",
    "    \n",
    "    return series\n",
    "\n",
    "def replace_values_with_dict(df, dictionary):\n",
    "    kolom_darah = [col for col in df.columns if apakah_bloodtype(df[col])]\n",
    "    df = df.apply(lambda x: x.str.strip().str.lower() if x.dtype == 'object' else x)\n",
    "    \n",
    "    for kolom in df.select_dtypes(include=['object']).columns:\n",
    "        # First replace values using dictionary\n",
    "        df[kolom] = df[kolom].replace(dictionary)\n",
    "        \n",
    "        # Apply format_typo only to values not in dictionary\n",
    "        df[kolom] = process_missing_dict_values(df[kolom], dictionary, format_typo)\n",
    "        \n",
    "        if kolom in kolom_darah:\n",
    "            df[kolom] = df[kolom].apply(lambda x: format_bloodtype(x, blood_mapping))\n",
    "        else:\n",
    "            df[kolom] = df[kolom].str.title()\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {\n",
    "    'america': 'USA',\n",
    "    'bharat': 'IND',\n",
    "    'uk': 'United Kingdom'\n",
    "}\n",
    "voting_mapping = {\n",
    "    'n': 'No', \n",
    "    'y': 'Yes',\n",
    "    ' ': 'Unknown',\n",
    "    '': 'Unknown',\n",
    "    np.nan: 'Unknown'\n",
    "}\n",
    "marital_mapping = {\n",
    "    's': 'Single',\n",
    "    'belummenikah': 'Single', \n",
    "    'janda': 'Widowed',\n",
    "    'duda': 'Widowed',\n",
    "    'cerai': 'Divorced'\n",
    "}\n",
    "education_mapping = {\n",
    "    'sma': 'High School',\n",
    "    'hs' : 'High School',\n",
    "    'phd' : 'Doctorate',\n",
    "    's1': 'Bachelors',\n",
    "    's2': 'Master',\n",
    "    's3': 'Doctorate'\n",
    "}\n",
    "gender_mapping = {\n",
    "    'm': 'Male',\n",
    "    'f': 'Female',\n",
    "    'u': 'Unknown',\n",
    "}\n",
    "blood_mapping = {\n",
    "    'positive': '+',\n",
    "    'negative': '-',\n",
    "    'positif': '+',\n",
    "    'negatif': '-',\n",
    "}\n",
    "\n",
    "def merge_dictionaries(*dicts):\n",
    "    merged_dict = {}\n",
    "    for dictionary in dicts:\n",
    "        merged_dict.update(dictionary)\n",
    "    return merged_dict\n",
    "\n",
    "def apakah_bloodtype(kolom):\n",
    "    akhiran = kolom.str.endswith('+') | kolom.str.endswith('-')\n",
    "    ada_kata = kolom.str.contains('positive|negative|positif|negatif', case=False, na=False)\n",
    "    return akhiran.any() | ada_kata.any()\n",
    "\n",
    "def format_bloodtype(blood, dictionary):\n",
    "    output = blood\n",
    "    bloods = blood.lower()\n",
    "    bagian = bloods.split()\n",
    "    if len(bagian) == 2 and (bagian[0] in ['a', 'b', 'ab', 'o'] and bagian[1] in dictionary):\n",
    "        darah, tipe = bagian\n",
    "        tipe = dictionary.get(tipe.lower(), tipe)\n",
    "        return f\"{darah.upper()}{tipe}\"\n",
    "    elif len(bagian) == 1 and bagian[0][-1] in ['+', '-']:\n",
    "        return bagian[0].upper()\n",
    "    else:\n",
    "        return output\n",
    "\n",
    "# Format Typo\n",
    "spell = SpellChecker()\n",
    "@lru_cache(maxsize=None)\n",
    "def format_typo(typo):\n",
    "    hasil = str(spell.correction(typo))\n",
    "    if hasil.lower() == 'none':\n",
    "        return typo\n",
    "    return hasil.title()\n",
    "\n",
    "def process_missing_dict_values(series, dictionary, process_func):\n",
    "    \"\"\"\n",
    "    Check if values in a series are not in dictionary and apply a function\n",
    "    \n",
    "    Parameters:\n",
    "    series: pandas Series to check\n",
    "    dictionary: dictionary containing valid values\n",
    "    process_func: function to apply to values not in dictionary\n",
    "    \"\"\"\n",
    "    # Create mask for values not in dictionary\n",
    "    mask = ~series.str.lower().isin([k.lower() for k in dictionary.keys()])\n",
    "    \n",
    "    # Apply function only to values not in dictionary\n",
    "    series.loc[mask] = series.loc[mask].apply(process_func)\n",
    "    \n",
    "    return series\n",
    "\n",
    "def replace_values_with_dict(df, dictionary):\n",
    "    kolom_darah = [col for col in df.columns if apakah_bloodtype(df[col])]\n",
    "    df = df.apply(lambda x: x.str.strip().str.lower() if x.dtype == 'object' else x)\n",
    "    \n",
    "    for kolom in df.select_dtypes(include=['object']).columns:\n",
    "        # First replace values using dictionary\n",
    "        df[kolom] = df[kolom].replace(dictionary)\n",
    "        \n",
    "        # Apply format_typo only to values not in dictionary\n",
    "        df[kolom] = process_missing_dict_values(df[kolom], dictionary, format_typo)\n",
    "        \n",
    "        if kolom in kolom_darah:\n",
    "            df[kolom] = df[kolom].apply(lambda x: format_bloodtype(x, blood_mapping))\n",
    "        else:\n",
    "            df[kolom] = df[kolom].str.title()\n",
    "            \n",
    "    return df\n",
    "\n",
    "merged_dict = merge_dictionaries(\n",
    "    country_mapping, \n",
    "    voting_mapping, \n",
    "    marital_mapping,\n",
    "    education_mapping,\n",
    "    gender_mapping,\n",
    "    blood_mapping\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buang Kolom Tidak Perlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665\n",
      "DF 1 ['Purchase_Date', 'Product_Description', 'Phone_Number', 'Email']\n",
      "DF 2 ['Name', 'Address', 'PassportNumber']\n",
      "DF 3 ['AdmissionDate', 'DischargeDate', 'Treatment', 'Doctor', 'Medication', 'TestResults', 'AppointmentDate']\n"
     ]
    }
   ],
   "source": [
    "def format_kolom_hapus(df, threshold = 0.6):\n",
    "    kolom_id = []\n",
    "    for kolom in df.select_dtypes(include=['object']).columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        jumlah = df[kolom].nunique()\n",
    "        # print(ratio)\n",
    "        if ratio >= threshold or jumlah > 100:\n",
    "            kolom_id.append(kolom)\n",
    "    return kolom_id\n",
    "\n",
    "print(df3['Medication'].nunique())\n",
    "print(f\"DF 1 {format_kolom_hapus(df1)}\")\n",
    "print(f\"DF 2 {format_kolom_hapus(df2)}\")\n",
    "print(f\"DF 3 {format_kolom_hapus(df3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2024-10-03\n",
       "1         2023-06-27\n",
       "2         2024-05-18\n",
       "3        Mar 11 1978\n",
       "4         2024-11-23\n",
       "            ...     \n",
       "10295     2024-03-16\n",
       "10296     2023-03-29\n",
       "10297    Oct 11 1998\n",
       "10298     2024-02-01\n",
       "10299    Mar 31 2017\n",
       "Name: AdmissionDate, Length: 10300, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['AdmissionDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Category\n",
      "Purchase_Date\n",
      "Product_Description\n",
      "Country\n",
      "Phone_Number\n",
      "Email\n",
      "Name\n",
      "Nationality\n",
      "Address\n",
      "VotingStatus\n",
      "PassportNumber\n",
      "MaritalStatus\n",
      "CriminalRecord\n",
      "EducationLevel\n",
      "AdmissionDate\n",
      "DischargeDate\n",
      "Diagnosis\n",
      "Treatment\n",
      "Doctor\n",
      "Department\n",
      "Gender\n",
      "BloodType\n",
      "Medication\n",
      "TestResults\n",
      "InsuranceProvider\n",
      "AppointmentDate\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "for kolom in df1.select_dtypes(include=['object']).columns:\n",
    "    print(kolom)\n",
    "for kolom in df2.select_dtypes(include=['object']).columns:\n",
    "    print(kolom)\n",
    "for kolom in df3.select_dtypes(include=['object']).columns:\n",
    "    print(kolom)\n",
    "print(df3['AdmissionDate'].dtype)\n",
    "print(df3['DischargeDate'].dtype)\n",
    "print(df3['AppointmentDate'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setelah Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_baru = pd.read_csv(\"clean-custdirty_data.csv\")\n",
    "df2_baru = pd.read_csv(\"clean-government_citizenship_dirty.csv\")\n",
    "df3_baru = pd.read_csv(\"clean-hospital_data_dirty.csv\")\n",
    "\n",
    "# df1_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdmissionDate</th>\n",
       "      <th>DischargeDate</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Department</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BloodType</th>\n",
       "      <th>BillingAmount</th>\n",
       "      <th>InsuranceProvider</th>\n",
       "      <th>AppointmentDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>Appendicitis</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>81</td>\n",
       "      <td>Female</td>\n",
       "      <td>Be</td>\n",
       "      <td>9495.73</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2024-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>End</td>\n",
       "      <td>88</td>\n",
       "      <td>M</td>\n",
       "      <td>Of</td>\n",
       "      <td>8681.08</td>\n",
       "      <td>Coinsurance</td>\n",
       "      <td>2023-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>2025-04-29</td>\n",
       "      <td>Appendicitis</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>94</td>\n",
       "      <td>M</td>\n",
       "      <td>Of</td>\n",
       "      <td>2829.42</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2024-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978-03-11</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>Cold</td>\n",
       "      <td>Endocrinology</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>1121.27</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2024-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Orth</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Be</td>\n",
       "      <td>5555.75</td>\n",
       "      <td>Coinsurance</td>\n",
       "      <td>2023-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>Endocrinology</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>5537.98</td>\n",
       "      <td>Coinsurance</td>\n",
       "      <td>2024-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>Cold</td>\n",
       "      <td>Endocrinology</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Appositive</td>\n",
       "      <td>3703.67</td>\n",
       "      <td>Healthplus</td>\n",
       "      <td>2024-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Cardie</td>\n",
       "      <td>90</td>\n",
       "      <td>U</td>\n",
       "      <td>Of</td>\n",
       "      <td>5659.97</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2024-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>Cold</td>\n",
       "      <td>Endocrinology</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>Negative</td>\n",
       "      <td>3511.16</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2024-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Cardie</td>\n",
       "      <td>59</td>\n",
       "      <td>Female</td>\n",
       "      <td>Abs</td>\n",
       "      <td>3445.49</td>\n",
       "      <td>Coinsurance</td>\n",
       "      <td>2024-10-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7030 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AdmissionDate DischargeDate     Diagnosis     Department  Age  Gender  \\\n",
       "0       2024-10-03    2025-05-11  Appendicitis    Orthopedics   81  Female   \n",
       "1       2023-06-27    2023-12-05      Fracture            End   88       M   \n",
       "2       2024-05-18    2025-04-29  Appendicitis    Orthopedics   94       M   \n",
       "3       1978-03-11    2019-10-26          Cold  Endocrinology   26       F   \n",
       "4       2024-11-23    2024-12-02      Diabetes           Orth   35  Female   \n",
       "...            ...           ...           ...            ...  ...     ...   \n",
       "7025    2024-11-06    2025-03-01      Fracture  Endocrinology   60       F   \n",
       "7026    2023-07-19    2024-09-16          Cold  Endocrinology    3    Male   \n",
       "7027    2023-04-18    2023-06-08      Diabetes         Cardie   90       U   \n",
       "7028    2024-01-03    2024-11-14          Cold  Endocrinology   35       F   \n",
       "7029    2024-04-12    2024-12-21      Diabetes         Cardie   59  Female   \n",
       "\n",
       "       BloodType  BillingAmount InsuranceProvider AppointmentDate  \n",
       "0             Be        9495.73           Unknown      2024-02-17  \n",
       "1             Of        8681.08       Coinsurance      2023-08-08  \n",
       "2             Of        2829.42           Unknown      2024-05-21  \n",
       "3              A        1121.27           Unknown      2024-11-03  \n",
       "4             Be        5555.75       Coinsurance      2023-11-14  \n",
       "...          ...            ...               ...             ...  \n",
       "7025           A        5537.98       Coinsurance      2024-12-03  \n",
       "7026  Appositive        3703.67        Healthplus      2024-07-03  \n",
       "7027          Of        5659.97           Unknown      2024-07-29  \n",
       "7028    Negative        3511.16           Unknown      2024-12-14  \n",
       "7029         Abs        3445.49       Coinsurance      2024-10-11  \n",
       "\n",
       "[7030 rows x 10 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Appendicitis', 'Fracture', 'Cold', 'Diabetes', 'Hypertension',\n",
       "       'Appendycytys'], dtype=object)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_baru['Diagnosis'] = df3_baru['Diagnosis'].apply(format_typo)\n",
    "df3_baru['Diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Category\n",
      "Purchase_Date\n",
      "Product_Description\n",
      "Country\n",
      "Phone_Number\n",
      "Email\n",
      "Name\n",
      "BirthDate\n",
      "Nationality\n",
      "Address\n",
      "VotingStatus\n",
      "PassportNumber\n",
      "MaritalStatus\n",
      "CriminalRecord\n",
      "EducationLevel\n",
      "AdmissionDate\n",
      "DischargeDate\n",
      "Diagnosis\n",
      "Department\n",
      "Gender\n",
      "BloodType\n",
      "InsuranceProvider\n",
      "AppointmentDate\n",
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      2024-02-17\n",
       "1      2023-08-08\n",
       "2      2024-05-21\n",
       "3      2024-11-03\n",
       "4      2023-11-14\n",
       "          ...    \n",
       "7025   2024-12-03\n",
       "7026   2024-07-03\n",
       "7027   2024-07-29\n",
       "7028   2024-12-14\n",
       "7029   2024-10-11\n",
       "Name: AppointmentDate, Length: 7030, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for kolom in df1_baru.select_dtypes(include=['object']).columns:\n",
    "    print(kolom)\n",
    "for kolom in df2_baru.select_dtypes(include=['object']).columns:\n",
    "    print(kolom)\n",
    "for kolom in df3_baru.select_dtypes(include=['object']).columns:\n",
    "    print(kolom)\n",
    "# print(df3_baru['AdmissionDate'].dtype)\n",
    "# print(df3_baru['DischargeDate'].dtype)\n",
    "print(df3_baru['AppointmentDate'].dtype)\n",
    "\n",
    "# df3_baru['AppointmentDate'].isna().sum() \n",
    "# df3_baru['AppointmentDate'] \n",
    "\n",
    "def safe_parse(date_str):\n",
    "    date_str = str(date_str).strip()\n",
    "    try:\n",
    "        parsed_date = parser.parse(date_str)\n",
    "        return pd.to_datetime(parsed_date)\n",
    "    except (ValueError, TypeError): \n",
    "        return pd.NaT \n",
    "\n",
    "df3_baru['AppointmentDate'] = df3_baru['AppointmentDate'].apply(safe_parse)\n",
    "df3_baru['AppointmentDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20327169274537696\n",
      "AdmissionDate\n",
      "0.19203413940256045\n",
      "DischargeDate\n",
      "0.0008534850640113798\n",
      "Diagnosis\n",
      "0.0008534850640113798\n",
      "Department\n",
      "0.01422475106685633\n",
      "Age\n",
      "0.0007112375533428165\n",
      "Gender\n",
      "0.0008534850640113798\n",
      "BloodType\n",
      "0.9706970128022759\n",
      "BillingAmount\n",
      "0.0007112375533428165\n",
      "InsuranceProvider\n",
      "0.10398293029871977\n",
      "AppointmentDate\n"
     ]
    }
   ],
   "source": [
    "def tes(df):\n",
    "    for kolom in df.columns:\n",
    "        ratio = df[kolom].nunique() / len(df)\n",
    "        print(ratio)\n",
    "        print(kolom)\n",
    "tes(df3_baru)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
